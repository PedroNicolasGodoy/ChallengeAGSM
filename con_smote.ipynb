{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_excel('C:/Users/Pedro/Desktop/DataScience-SoyHenry/AGSM--power bi/BASE PRUEBA BI.xlsx', sheet_name='DATOS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 1. Preprocesamiento y creación de la variable objetivo ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Estados exitosos\n",
    "estados_venta_exitosa = [\n",
    "    \"abierto en solicitud de plan de ahorro\",\n",
    "    \"abierto en preventa\"\n",
    "]\n",
    "\n",
    "#  Filtrar y crear target\n",
    "df_abiertos = df[df[\"Estado\"].str.lower().str.startswith(\"abierto\")].copy()\n",
    "df_abiertos[\"Venta_Exitosa\"] = df_abiertos[\"Estado\"].str.lower().apply(\n",
    "    lambda x: 1 if x in estados_venta_exitosa else 0\n",
    ")\n",
    "\n",
    "#  Variables derivadas\n",
    "df_abiertos[\"Cantidad_Supervisores\"] = df_abiertos[\"Supervisores\"].astype(str).apply(lambda x: len(x.split(\",\")))\n",
    "df_abiertos[\"Dia_Semana\"] = pd.to_datetime(df_abiertos[\"Fecha alta\"], errors='coerce').dt.dayofweek\n",
    "df_abiertos[\"Días\"] = pd.to_numeric(df_abiertos[\"Días\"], errors='coerce')\n",
    "\n",
    "#  Features y target\n",
    "features = [\n",
    "    \"Días\", \"Cantidad_Supervisores\", \"Dia_Semana\",\n",
    "    \"Origen\", \"Tipo de operación\", \"Rubro\", \"Categoría\", \"Tipo\", \"Tipo de Proceso Comercial\"\n",
    "]\n",
    "X = df_abiertos[features].copy()\n",
    "y = df_abiertos[\"Venta_Exitosa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 2. Preprocesamiento y entrenamiento del modelo ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\AppData\\Local\\Temp\\ipykernel_12044\\1284883424.py:3: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if X[col].dtype == \"object\" or pd.api.types.is_categorical_dtype(X[col]) or pd.api.types.is_datetime64_any_dtype(X[col]):\n"
     ]
    }
   ],
   "source": [
    "#  Convertir columnas categóricas a string\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\" or pd.api.types.is_categorical_dtype(X[col]) or pd.api.types.is_datetime64_any_dtype(X[col]):\n",
    "        X[col] = X[col].astype(str)\n",
    "\n",
    "#  Dividir\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "#  Detectar tipos de columnas\n",
    "numeric_features = [\"Días\", \"Cantidad_Supervisores\", \"Dia_Semana\"]\n",
    "categorical_features = [\"Origen\", \"Tipo de operación\", \"Rubro\", \"Categoría\", \"Tipo\", \"Tipo de Proceso Comercial\"]\n",
    "\n",
    "#  Pipelines de transformación\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "#  Pipeline final con SMOTE y modelo\n",
    "pipeline = ImbPipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\"classifier\", GradientBoostingClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n"
     ]
    }
   ],
   "source": [
    "print(type(clf))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- 3. Seleccionar variables de entrada (features) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9826086956521739\n",
      "ROC AUC: 0.99210669569951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        11\n",
      "           1       0.99      0.99      0.99       334\n",
      "\n",
      "    accuracy                           0.98       345\n",
      "   macro avg       0.86      0.86      0.86       345\n",
      "weighted avg       0.98      0.98      0.98       345\n",
      "\n",
      "Importancia de características:\n",
      "                            Feature    Importance\n",
      "0                              Días  9.897823e-01\n",
      "153                       Rubro_nan  5.958729e-03\n",
      "9               Origen_Landing_Page  3.047721e-03\n",
      "5              Origen_Facebook_Form  4.771660e-04\n",
      "1             Cantidad_Supervisores  2.329209e-04\n",
      "7             Origen_Instagram_Form  1.805547e-04\n",
      "275  Tipo de Proceso Comercial_Otro  1.409209e-04\n",
      "274  Tipo de Proceso Comercial_Cero  1.318234e-04\n",
      "276  Tipo de Proceso Comercial_Plan  2.447065e-05\n",
      "3               Origen_Bot_Whatsapp  1.034048e-05\n",
      "21     Tipo de operación_FINANCIADO  3.176833e-06\n",
      "22            Tipo de operación_nan  3.116933e-06\n",
      "14           Origen_Salón de Ventas  2.344507e-06\n",
      "2                        Dia_Semana  2.313046e-06\n",
      "16                     Origen_Stand  1.638641e-06\n",
      "256                   Categoría_nan  2.040827e-07\n",
      "189              Categoría_Comercio  1.464832e-07\n",
      "191           Categoría_Dependencia  8.647754e-08\n",
      "138             Rubro_independiente  2.939902e-09\n",
      "104                   Rubro_celador  1.317629e-09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Entrenar\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#  Predicciones y métricas\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#  Importancia de variables\n",
    "preprocessor_fitted = pipeline.named_steps[\"preprocessor\"]\n",
    "numeric_feature_names = preprocessor_fitted.transformers_[0][2]\n",
    "categorical_encoder = preprocessor_fitted.transformers_[1][1].named_steps[\"onehot\"]\n",
    "categorical_feature_names = categorical_encoder.get_feature_names_out(categorical_features)\n",
    "feature_names = list(numeric_feature_names) + list(categorical_feature_names)\n",
    "importances = pipeline.named_steps[\"classifier\"].feature_importances_\n",
    "\n",
    "importancia_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Importancia de características:\")\n",
    "print(importancia_df.head(20))\n",
    "importancia_df.to_csv(\"importancia_modelo_con_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y_test_con_smote.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar para Streamlit\n",
    "joblib.dump(pipeline, \"modelo_con_smote.pkl\")\n",
    "joblib.dump(preprocessor.transform(X_test), \"X_test_con_smote.pkl\")\n",
    "joblib.dump(y_test, \"y_test_con_smote.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
